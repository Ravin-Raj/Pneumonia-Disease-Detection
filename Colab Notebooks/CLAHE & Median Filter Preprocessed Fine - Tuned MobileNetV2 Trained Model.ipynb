{"cells":[{"cell_type":"markdown","metadata":{"id":"5rBkUdS5cMUj"},"source":["CLAHE & Median Filter Preprocessed Fine - Tuned MobileNetV2 Trained Model.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcxcrDlwLHMu","outputId":"bf5b2b3b-22c2-4440-b047-fc95db1b4287"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found 3477 images belonging to 3 classes.\n","Found 498 images belonging to 3 classes.\n","Found 993 images belonging to 3 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-a590d6ef6705>:83: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: ['keras_tensor_159']\n","Received: inputs=Tensor(shape=(None, 224, 224, 3))\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.5057 - loss: 1.0448\n","Epoch 1: val_accuracy improved from -inf to 0.69880, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 835ms/step - accuracy: 0.5063 - loss: 1.0439 - val_accuracy: 0.6988 - val_loss: 0.7293\n","Epoch 2/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - accuracy: 0.6712 - loss: 0.8071\n","Epoch 2: val_accuracy improved from 0.69880 to 0.74096, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 773ms/step - accuracy: 0.6713 - loss: 0.8069 - val_accuracy: 0.7410 - val_loss: 0.6820\n","Epoch 3/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.7171 - loss: 0.7376\n","Epoch 3: val_accuracy improved from 0.74096 to 0.76707, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 771ms/step - accuracy: 0.7170 - loss: 0.7376 - val_accuracy: 0.7671 - val_loss: 0.6596\n","Epoch 4/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.7440 - loss: 0.7109\n","Epoch 4: val_accuracy improved from 0.76707 to 0.77912, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 790ms/step - accuracy: 0.7439 - loss: 0.7110 - val_accuracy: 0.7791 - val_loss: 0.6461\n","Epoch 5/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - accuracy: 0.7408 - loss: 0.7163\n","Epoch 5: val_accuracy improved from 0.77912 to 0.78514, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 781ms/step - accuracy: 0.7408 - loss: 0.7161 - val_accuracy: 0.7851 - val_loss: 0.6381\n","Epoch 6/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.7380 - loss: 0.7002\n","Epoch 6: val_accuracy did not improve from 0.78514\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 780ms/step - accuracy: 0.7381 - loss: 0.7002 - val_accuracy: 0.7751 - val_loss: 0.6523\n","Epoch 7/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.7544 - loss: 0.6873\n","Epoch 7: val_accuracy improved from 0.78514 to 0.78916, saving model to /content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 785ms/step - accuracy: 0.7544 - loss: 0.6873 - val_accuracy: 0.7892 - val_loss: 0.6297\n","Epoch 8/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.7505 - loss: 0.6876\n","Epoch 8: val_accuracy did not improve from 0.78916\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 770ms/step - accuracy: 0.7505 - loss: 0.6876 - val_accuracy: 0.7771 - val_loss: 0.6294\n","Epoch 9/25\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.7746 - loss: 0.6670\n","Epoch 9: val_accuracy did not improve from 0.78916\n","\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 778ms/step - accuracy: 0.7745 - loss: 0.6670 - val_accuracy: 0.7831 - val_loss: 0.6486\n","Epoch 10/25\n","\u001b[1m 94/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10s\u001b[0m 709ms/step - accuracy: 0.7736 - loss: 0.6642"]}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Paths\n","train_dir = \"/content/drive/MyDrive/Pneumonia Disease Detection CLAHE & Median Filter Preprocessed Dataset/Training Data\"\n","val_dir = \"/content/drive/MyDrive/Pneumonia Disease Detection CLAHE & Median Filter Preprocessed Dataset/Validation Data\"\n","test_dir = \"/content/drive/MyDrive/Pneumonia Disease Detection CLAHE & Median Filter Preprocessed Dataset/Testing Data\"\n","\n","# Image settings\n","img_size = (224, 224)\n","batch_size = 32\n","epochs = 25\n","\n","# Data augmentation for training\n","train_aug = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","train_gen = train_aug.flow_from_directory(\n","    train_dir,\n","    target_size=img_size,\n","    color_mode='rgb',\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True\n",")\n","\n","# Validation and test generators (no augmentation)\n","val_test_aug = ImageDataGenerator(rescale=1./255)\n","\n","val_gen = val_test_aug.flow_from_directory(\n","    val_dir,\n","    target_size=img_size,\n","    color_mode='rgb',\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","test_gen = val_test_aug.flow_from_directory(\n","    test_dir,\n","    target_size=img_size,\n","    color_mode='rgb',\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False\n",")\n","\n","# Get number of classes\n","num_classes = len(train_gen.class_indices)\n","\n","# Compute class weights\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(train_gen.classes),\n","    y=train_gen.classes\n",")\n","class_weights_dict = dict(enumerate(class_weights))\n","\n","# Load base model\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","base_model.trainable = False  # Freeze initial layers\n","\n","# Add custom layers\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(128, activation='relu')(x)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile model with label smoothing\n","loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss=loss_fn, metrics=['accuracy'])\n","\n","# Checkpoint callback\n","checkpoint_path = '/content/drive/MyDrive/Pneumonia_MobileNetV2_Best_Model_Initial.h5'\n","checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n","\n","# Initial training\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=epochs,\n","    callbacks=[checkpoint],\n","    class_weight=class_weights_dict\n",")\n","\n","# Unfreeze some layers for fine-tuning\n","base_model.trainable = True\n","fine_tune_at = 100\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# Recompile with lower learning rate\n","model.compile(optimizer=Adam(learning_rate=1e-5), loss=loss_fn, metrics=['accuracy'])\n","\n","# Fine-tune training\n","checkpoint_path_finetuned = '/content/drive/MyDrive/Pneumonia_MobileNetV2_FineTuned_Model.h5'\n","fine_tune_checkpoint = ModelCheckpoint(checkpoint_path_finetuned, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n","\n","history_finetune = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=10,  # Optional: increase if needed\n","    callbacks=[fine_tune_checkpoint],\n","    class_weight=class_weights_dict\n",")\n","\n","# Evaluate model on test data\n","loss, acc = model.evaluate(test_gen, verbose=1)\n","print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n","\n","# Classification report\n","Y_pred = model.predict(test_gen)\n","y_pred = np.argmax(Y_pred, axis=1)\n","y_true = test_gen.classes\n","class_labels = list(test_gen.class_indices.keys())\n","print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=class_labels))\n","\n","# Confusion Matrix\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP7SiuiZHl4KAOlTzEmBP87"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}